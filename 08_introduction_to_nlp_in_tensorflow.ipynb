{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arindam2002/tensorflow_learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow"
      ],
      "metadata": {
        "id": "O4vBnz4R1yeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for GPU"
      ],
      "metadata": {
        "id": "5WK0x7JAmikl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "J9hsKRLOmuHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85917318-5fc8-4e65-adf3-2e75c91f16bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-28364eb1-2407-e0d2-08a8-55845b9bfe74)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions"
      ],
      "metadata": {
        "id": "IgdMBQjQnJZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Arindam2002/tensorflow_learning/main/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHnveIiGnmjP",
        "outputId": "c30011fd-9e0b-497a-fa0f-1913e6439015"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-20 07:58:17--  https://raw.githubusercontent.com/Arindam2002/tensorflow_learning/main/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10857 (11K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-20 07:58:18 (76.1 MB/s) - ‘helper_functions.py’ saved [10857/10857]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "KDIMoYUcn4cZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get text dataset\n",
        "\n",
        "We're gonna be using Kaggle's introduction to NLP dataset (text samples of Tweets labelled as diaster or not diaster).\n",
        "\n",
        "Dataset: https://www.kaggle.com/c/nlp-getting-started"
      ],
      "metadata": {
        "id": "4Umo8VeKoGOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "eQm9w1groeOz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "slSTOOltpv0E",
        "outputId": "2260e186-0856-45d1-e4b2-e99790db4208"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0aefab5d-f876-4d8a-9457-b0bed6773d38\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0aefab5d-f876-4d8a-9457-b0bed6773d38\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"arindamupadhyay\",\"key\":\"2f332cb7d802f0730f66d81386086181\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "aVEoshVgp4Zm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c 'nlp-getting-started'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCNXWq7AqfRV",
        "outputId": "e11ccab4-00b0-4681-a43a-44ba48cd6760"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading nlp-getting-started.zip to /content\n",
            "\r  0% 0.00/593k [00:00<?, ?B/s]\n",
            "\r100% 593k/593k [00:00<00:00, 19.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip nlp-getting-started.zip -d nlp-getting-started"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4_MFcLQqudW",
        "outputId": "196bc0ca-6006-406b-b99a-1ebdb1521f0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nlp-getting-started.zip\n",
            "  inflating: nlp-getting-started/sample_submission.csv  \n",
            "  inflating: nlp-getting-started/test.csv  \n",
            "  inflating: nlp-getting-started/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But let's get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ],
      "metadata": {
        "id": "WuPQtvH9rLko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/content/nlp-getting-started/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/nlp-getting-started/test.csv\")\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8u8By43prxk5",
        "outputId": "2bebf0c8-9d28-4d25-a3e3-a46408d7a142"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2ed06ff-2162-4ca4-adf0-b2cfa3950cf5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2ed06ff-2162-4ca4-adf0-b2cfa3950cf5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2ed06ff-2162-4ca4-adf0-b2cfa3950cf5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2ed06ff-2162-4ca4-adf0-b2cfa3950cf5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "vzbq37jkx0br",
        "outputId": "972a9629-8546-4857-8add-5178c9c05a3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95b734ef-5336-455e-80f8-110868b55a5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95b734ef-5336-455e-80f8-110868b55a5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95b734ef-5336-455e-80f8-110868b55a5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95b734ef-5336-455e-80f8-110868b55a5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out test dataframe\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jssNpVxQyPdm",
        "outputId": "16e38dad-b3d2-4883-dae0-10ae22953547"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07375f2d-47a5-4688-8947-8c7818dbbaf6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07375f2d-47a5-4688-8947-8c7818dbbaf6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07375f2d-47a5-4688-8947-8c7818dbbaf6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07375f2d-47a5-4688-8947-8c7818dbbaf6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of examples of each class\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qn1k571yeGd",
        "outputId": "e7104f86-ff6c-4ebb-ead1-dd3585be5e84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This is a slightly imbalanced dataset.\n",
        "\n",
        "> In case of a highly imbalanced dataset, refer: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data"
      ],
      "metadata": {
        "id": "hHpRK6j1zIW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total samples\n",
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJbuZVX-yvMV",
        "outputId": "23c4b556-be92-48f2-f8d3-b00d144611ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real diaster)\" if target > 0 else \"(not real diaster)\")\n",
        "  print(f\"Text: {text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef7V4am10raB",
        "outputId": "fab44863-1968-4552-f5dc-69daed2e8c88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real diaster)\n",
            "Text: I JUST SCREAMED IN 57 LANGUAGES THIS IS SO GOOD https://t.co/ldjet9tfMk\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real diaster)\n",
            "Text: Fear and panic in the air I want to be free from desolation and despair!\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real diaster)\n",
            "Text: This Friday!! Palm Beach County #Grindhouse Series one night screening of  #TexasChainsawMassacre http://t.co/1WopsGbVvv @morbidmovies\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real diaster)\n",
            "Text: wowo--=== 12000 Nigerian refugees repatriated from Cameroon\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real diaster)\n",
            "Text: http://t.co/pTKrXtZjtV  Nashville Theater Attack: Will Gun Grabbers Now Demand ÛÏHatchet Control?Û\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation sets\n",
        "\n",
        "We want to be able to see how our model is performing on unseen data whilst it trains.\n",
        "\n",
        "And because the testing dataset doesn't have labels, we'll have to create a validation dataset to evaluate on (the model won't see the validation dataset during training so we can use its samples and labels to evaluate our model's performance)."
      ],
      "metadata": {
        "id": "j4RhiNzn2EnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Bmpsgrns4pN3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split the training data into training & validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,    # use 10% of training data for validation split\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "vs0lrvT1P485"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check lengths of new datasets\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcXGPv0QX4sT",
        "outputId": "7b0de78d-6582-403c-a9a7-f95ce859dc00"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nnGUz0fYJ-d",
        "outputId": "cb2ab1bb-cd60-4ed3-c2e9-fa28a0525e2e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things we have to do before we can build a model is to convert our text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenziation - direct mapping of token (a token could be a word or a character) to number\n",
        "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
      ],
      "metadata": {
        "id": "BKkcxQCnYdAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text vectorization (tokenization)"
      ],
      "metadata": {
        "id": "Iwm4QbBcYoIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa70wuD4hk58",
        "outputId": "f0855c4d-c8a6-4117-dcff-827f90dc55b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.common import standardize_mapping\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None,   # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                     standardize=\"lower_and_strip_punctuation\",   # how to process text\n",
        "                                     split=\"whitespace\",    # how to split tokens\n",
        "                                     ngrams=None,   # create groups of n-words\n",
        "                                     output_mode=\"int\",   # how to map tokens to numbers\n",
        "                                     output_sequence_length=None,   # how long should the output sequence of tokens be?\n",
        "                                    #  pad_to_max_tokens=True   # Not valid if using max_tokens=None\n",
        "                                     )"
      ],
      "metadata": {
        "id": "ZdTWio_9dJEF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences[0].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBZKYE25l7T3",
        "outputId": "0fa968c2-a437-4a22-cf3a-2880d95a157c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the avg number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt12RKgKhvjq",
        "outputId": "1632909b-49a3-47cc-a4bb-1da4fd88b0ff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000    # max number of words to have in our vocabulary\n",
        "max_length = 15   # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "GjpEQHsfmHT1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "lXP5QHycmrtG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R86Y0tceCyxH",
        "outputId": "dba6ea80-21f3-4714-c0e3-89d9ed807637"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence} \\\n",
        "        \\n\\nVectorized version: \\n{text_vectorizer([random_sentence])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTDGV9UEEbA9",
        "outputId": "18cd97c1-e5a4-4723-eced-db748de9e38c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "@_chelsdelong12 @kendra_leigh13 I'll crash it         \n",
            "\n",
            "Vectorized version: \n",
            "[[  1   1 421  85  15   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()   # Get all the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5]                    # the most common words in the vocab\n",
        "bottom_5_words = words_in_vocab[-5:]                # the least common words in the vocab\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Most 5 common words in vocab: {top_5_words}\")\n",
        "print(f\"Least 5 common words in vocab: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0FeTyE_FLr1",
        "outputId": "899f2cd9-9e60-41d7-d54e-16abe24009b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Most 5 common words in vocab: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Least 5 common words in vocab: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Embedding using an Embedding Layer\n",
        "\n",
        "    Turns positive integers (indexes) into dense vectors of fixed size\n",
        "\n",
        "[`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution and modifies itself as the model trains. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer."
      ],
      "metadata": {
        "id": "N2J8OId5GW6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,    # Prefer a multiple of 8 for faster computation\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length)\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOO-37qrHfHK",
        "outputId": "60f93a09-bfa1-484d-82a1-26f9ae2ff173"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fc3565b1d90>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence} \\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)...\n",
        "# First we gotta turn our sentence into integer form since embedding layer Turns positive integers (indexes) into dense vectors of fixed size\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWwfYajk-VDh",
        "outputId": "1297b5aa-ff06-4315-a3c2-b0e16bef5e19"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "@olrules Welcome - Read a free chapter of my new book Encounters With Jesus. It's full of hope. http://t.co/6qX7arf4AG         \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.0292994 , -0.0291266 , -0.03911811, ...,  0.00065811,\n",
              "         -0.04494727,  0.00993083],\n",
              "        [-0.04124365, -0.01828172,  0.00555946, ...,  0.02010162,\n",
              "         -0.00851266,  0.02548548],\n",
              "        [ 0.02467858,  0.00598794,  0.01228527, ...,  0.04410759,\n",
              "         -0.02241321,  0.00102876],\n",
              "        ...,\n",
              "        [ 0.02970538, -0.045256  ,  0.03756801, ..., -0.00240166,\n",
              "         -0.03264445, -0.01893859],\n",
              "        [-0.02345494,  0.00255754,  0.00564493, ...,  0.02866813,\n",
              "          0.01739612,  0.03217764],\n",
              "        [ 0.0149958 ,  0.03080846, -0.00451688, ..., -0.00737882,\n",
              "          0.01325226,  0.02621965]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding (first word of the random sentence)\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O8JibqiBcje",
        "outputId": "f7205c9e-c6ae-4cc2-d544-a2c98a4f75b3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.0292994 , -0.0291266 , -0.03911811, -0.0162711 , -0.03821252,\n",
              "         0.04943268,  0.04634644, -0.04111554, -0.01783438,  0.03181769,\n",
              "        -0.0469859 , -0.01796906, -0.02213192, -0.03415477, -0.04163855,\n",
              "         0.044303  , -0.04164295, -0.01372989,  0.03119539, -0.01794648,\n",
              "         0.01814151,  0.04700426, -0.00786752, -0.03900969, -0.003588  ,\n",
              "         0.02873996, -0.00596328,  0.01523087, -0.03659713,  0.04747016,\n",
              "        -0.016645  , -0.03871424, -0.04469598,  0.01231394,  0.01007832,\n",
              "         0.00946035, -0.02571931, -0.01919539,  0.0403966 ,  0.0272916 ,\n",
              "        -0.04900105,  0.02550776, -0.00673159,  0.04216984,  0.02358594,\n",
              "         0.03150092, -0.01818534,  0.04349276,  0.01350049,  0.03010071,\n",
              "         0.04803336,  0.03884185, -0.01543299, -0.04829922, -0.02768956,\n",
              "        -0.04935468, -0.0067266 ,  0.03330794,  0.01507351, -0.00637012,\n",
              "         0.01790548,  0.01630897, -0.00526017, -0.01110787,  0.04629321,\n",
              "         0.04848243,  0.04464724, -0.00735618,  0.00643151,  0.01954355,\n",
              "        -0.04958098, -0.00188762, -0.04122897,  0.01479277,  0.03181341,\n",
              "        -0.0401836 ,  0.04236916, -0.00395473,  0.0001454 ,  0.00632594,\n",
              "         0.00038815,  0.03194063, -0.02184821, -0.02132004, -0.02730421,\n",
              "         0.00286443, -0.00879394,  0.00584954, -0.03166068, -0.02108247,\n",
              "         0.01343235,  0.03876794, -0.01743077,  0.02216352, -0.02069711,\n",
              "        -0.01213632, -0.02109923, -0.04252071,  0.00506493, -0.03774815,\n",
              "         0.01837254, -0.03668717,  0.00418141,  0.04009911,  0.04400564,\n",
              "        -0.0208813 ,  0.01903678, -0.02824451,  0.00124189, -0.04603895,\n",
              "         0.04175192, -0.00781881, -0.01607219,  0.01128332,  0.02656987,\n",
              "        -0.04561238, -0.03095802, -0.04742634,  0.04523288,  0.0215092 ,\n",
              "         0.01141686,  0.02657497, -0.01860535, -0.00916748,  0.04237998,\n",
              "         0.00065811, -0.04494727,  0.00993083], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \"@olrules Welcome - Read a free chapter of my new book Encounters With Jesus. It's full of hope. http://t.co/6qX7arf4AG\")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset (setting up modelling experiments)\n",
        "\n",
        "Now we've got our data in numerical format, let's start building and comparing different models.\n",
        "\n",
        "* Model 0: Naive Bayes (baseline) - got this from here: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model\n",
        "* Model 3: GRU model\n",
        "* Model 4: Bidirectional LSTM\n",
        "* Model 5: 1D Convolutional Neural Network\n",
        "* Model 6: TensorFlow Hub Pretrained Word Embedding (feature extractor)\n",
        "* Model 7: Same as model 6 but using 10% of data\n",
        "\n",
        "For each of these models, we're going to be following the TensorFlow steps in modelling:\n",
        "* Create a model\n",
        "* Fit the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison"
      ],
      "metadata": {
        "id": "FJaV9lm0DMSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "> **Note:** It's common practice to use non-DL algorithms as a baseline because of their speed & then later using DL to see if we can improve upon them.\n"
      ],
      "metadata": {
        "id": "oBftGp_IOTPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()),   # convert words to numbers using tfidf\n",
        "                    ('clf', MultinomialNB())        # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qd2scQasqO3",
        "outputId": "547aff0d-8db5-43e8-c93c-dca6b8d3e88f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM0x0-jMtreg",
        "outputId": "b2f63c4e-6801-40ab-bf8c-d92c0021113d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_oZMIzEwpjb",
        "outputId": "4bc15669-96a1-4372-86ee-ad811b7505ba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "Let's create a function to evaluate our modelling experiment predictions using: \n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ],
      "metadata": {
        "id": "an7I-JbOyKPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  ----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted label in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall and f1-score between y_true and y_pred.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate model accuracy \n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Calculate model precision, recall & f1 score using weighted averag\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "\n",
        "  # Create a dictionary of model results\n",
        "  model_results = {\n",
        "      \"accuracy\": model_accuracy,\n",
        "      \"precision\": model_precision,\n",
        "      \"recall\": model_recall,\n",
        "      \"f1\": model_f1\n",
        "  }\n",
        "\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "2SjZLX9ny-OX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbEgRoOuYQ4g",
        "outputId": "f7804f2d-87c4-4ab9-8e15-22de1142e6ed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "5JuzLTeaaTUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback (nned to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save tensorboard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "zPAC-59rpjst"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)    # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs)   # turn the input text into numbers\n",
        "x = embedding(x)    # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x)    # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)    # Create the output layer (since binary outputs, use sigmoid activation function)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "metadata": {
        "id": "EquLarL2iSo8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Our model takes a 1-dimensional string as input (in our case, a Tweet), it then tokenizes the string using `text_vectorizer` and creates an embedding using `embedding`.\n",
        "\n",
        "We then pool the outputs of the embedding layer to reduce the dimensionality of the tensor we pass to the output layer. (**Note:** This is necessary to match output dimension of our network with label dimension...We can use `GlobalAveragePooling1D()`, `GlobalAveragePooling2D()` or `GlobalAveragePooling3D()` depending on the data shape.)\n",
        "\n",
        "Finally, we pass the output of the pooling layer to a dense layer with sigmoid activation (we use sigmoid since our problem is binary classification).\n",
        "\n",
        "Before we can fit our model to the data, we've got to compile it. Since we're working with binary classification, we'll use `\"binary_crossentropy\"` as our loss function and the Adam optimizer."
      ],
      "metadata": {
        "id": "Z3HVEmJGnT50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzs8pE6Bj9ew",
        "outputId": "f3dca279-92c2-44bb-fcc2-6204a3218b54"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Y5bl5p3rkAeR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8-RekbLklNd",
        "outputId": "c2c89260-4724-4f63-d44d-b9d665fc9bb9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20220720-075841\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 9ms/step - loss: 0.6113 - accuracy: 0.6981 - val_loss: 0.5411 - val_accuracy: 0.7454\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.4427 - accuracy: 0.8180 - val_loss: 0.4713 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3467 - accuracy: 0.8591 - val_loss: 0.4584 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2850 - accuracy: 0.8898 - val_loss: 0.4605 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.2380 - accuracy: 0.9114 - val_loss: 0.4780 - val_accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1sDCKZzkwPQ",
        "outputId": "4c2a9e3e-830c-412e-efab-db7de3508dc1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.7835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47796574234962463, 0.7834645509719849]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a few predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[0], val_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQPmFbPZoVJH",
        "outputId": "e0e90f4f-be2f-4180-eb9c-e5dde1babf3b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.41853407], dtype=float32),\n",
              " 'DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9bWxq0eolfG",
        "outputId": "6b192672-92b4-481a-c64c-f77d0ddf58d7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umaU_GmKqnGS",
        "outputId": "1df0553f-84e2-41b4-e902-dc25378d39a5"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.34645669291339,\n",
              " 'f1': 0.7807800582578167,\n",
              " 'precision': 0.7872123378365872,\n",
              " 'recall': 0.7834645669291339}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9LpfyE1r6ul",
        "outputId": "7b2d8b00-7d13-470b-827e-54102dc2aa1b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing learned embeddings\n",
        "\n",
        "To further understand word embeddings, let's visualize them, to do so, we'll get the weights matrix (embedding matrix) from our embedding layer and visualize it using the Embedding project tool, see the TensorFlow guide for more: https://www.tensorflow.org/tutorials/text/word_embeddings"
      ],
      "metadata": {
        "id": "jtvzMZU3xl57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGD8ezO5x3rq",
        "outputId": "a73ff567-eea0-498f-e96e-a23e9b8c655a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP4dEH0k0adW",
        "outputId": "3120e1d7-18ff-4d92-ff45-164b2d3a4fb7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embeddig layer\n",
        "# (the weights are the numerical patterns between the text in the training dataset that the model has learned)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape   # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SLQFTXz7pJ4",
        "outputId": "bca8a4d2-b2ab-492b-fe5b-1fa3d5cb0cc5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now we've got the embedding matrix our model has learned to represent our tokens... Let's see how we can visualize it.\n",
        "\n",
        "> To do so, TensorFlow has a handy tool called projector: https://projector.tensorflow.org/\n",
        "\n",
        "> And TensorFlow also has an incredible guide on word embeddings themselves: https://www.tensorflow.org/tutorials/text/word_embeddings"
      ],
      "metadata": {
        "id": "pfQI7_N-9b9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "# Code to save trained embeddings to file - we got this from here: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "B067vaBx8Ir7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download files from colab to upload to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "_HTsjHto_K4j",
        "outputId": "566cdab1-e2b6-4fee-f0e5-704af1ac3712"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da410684-8dff-4f24-bdd0-d9e1486e5930\", \"vectors.tsv\", 15380756)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a38df3ab-70b6-48bf-bf5e-a5b05b04ad29\", \"metadata.tsv\", 80388)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our visual word embeddings might not look like much to us, but they help our model understand the relationships between words.\n",
        "\n",
        "For more on a popular type of word embedding and more visual explanations check out the illustrated word2vec: https://jalammar.github.io/illustrated-word2vec/"
      ],
      "metadata": {
        "id": "STyL2fSjN0kJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**.\n",
        "\n",
        ">***The premise of an RNN is to use the representation of a previous input to aid the representation of a later input***\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (`X`) and compute an output (`y`) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog. \n",
        "\n",
        "See what happened there? \n",
        "\n",
        "I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n",
        "\n",
        "When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence. \n",
        "\n",
        "For a simple example, take two sentences:\n",
        "1. Massive earthquake last week, no?\n",
        "2. No massive earthquake last week.\n",
        "\n",
        "Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n",
        "\n",
        "Recurrent neural networks can be used for a number of sequence-based problems:\n",
        "* **One to one:** one input, one output, such as image classification.\n",
        "* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "* Long short-term memory cells (LSTMs).\n",
        "* Gated recurrent units (GRUs).\n",
        "* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n",
        "Going into the details of each these is beyond the scope of this notebook (we're going to focus on using them instead), the main thing you should know for now is that they've proven very effective at modelling sequences.\n",
        "\n",
        "For a deeper understanding of what's happening behind the scenes of the code we're about to write, I'd recommend the following resources:\n",
        "\n",
        "> 📖 **Resources:**\n",
        "> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) - explains the background of recurrent neural networks and introduces LSTMs.\n",
        "> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block.\n"
      ],
      "metadata": {
        "id": "m6XK2bEAU05j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "With all this talk of what RNN's are and what they're good for, I'm sure you're eager to build one.\n",
        "\n",
        "We're going to start with an LSTM-powered RNN.\n",
        "\n",
        "To harness the power of the LSTM cell (LSTM cell and LSTM layer are often used interchangably) in TensorFlow, we'll use [`tensorflow.keras.layers.LSTM()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM).\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-RNN-architecture-coloured-block-edition.png)\n",
        "*Coloured block example of the structure of an recurrent neural network.*\n",
        "\n",
        "Our model is going to take on a very similar structure to `model_1`:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "The main difference will be that we're going to add an LSTM layer between our embedding and output.\n",
        "\n",
        "And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer (`model_2_embedding`) for our model. The `text_vectorizer` layer can be reused since it doesn't get updated during training.\n",
        "\n",
        "> 🔑 **Note:** The reason we use a new embedding layer for each model is since the embedding layer is a *learned* representation of words (as numbers), if we were to use the same embedding layer (`embedding_1`) for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."
      ],
      "metadata": {
        "id": "KEwhoC3bU5_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x)   # when we're stacking RNN cells together, we need to set return_sequences = True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(units=64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(units=64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "metadata": {
        "id": "ir43geqnWyi1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBX20xujY_nW",
        "outputId": "e499971f-c064-4a85-d715-bffa9273a88d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "k2hOnLuBcfli"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_2_LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcw7uEW3cyhT",
        "outputId": "b996f1b5-1801-444e-aada-b55e83623e6b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220720-075908\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 8ms/step - loss: 0.2234 - accuracy: 0.9232 - val_loss: 0.5437 - val_accuracy: 0.7874\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1587 - accuracy: 0.9445 - val_loss: 0.6344 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1274 - accuracy: 0.9502 - val_loss: 0.6781 - val_accuracy: 0.7822\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.1065 - accuracy: 0.9575 - val_loss: 0.7726 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0891 - accuracy: 0.9660 - val_loss: 0.8443 - val_accuracy: 0.7756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prdictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boBtSSSSdVXU",
        "outputId": "086eb677-ac37-4f95-ec4e-baf5760af482"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.4937216e-03],\n",
              "       [8.6211991e-01],\n",
              "       [9.9953640e-01],\n",
              "       [3.3078786e-02],\n",
              "       [5.6151405e-04],\n",
              "       [9.6289885e-01],\n",
              "       [4.8877928e-01],\n",
              "       [9.9955863e-01],\n",
              "       [9.9910468e-01],\n",
              "       [5.4922515e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTTW5MUhdq9C",
        "outputId": "2e018718-891f-4619-a1fa-e7f03f52ab85"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6R6ld4ld9BI",
        "outputId": "5ad4e430-9068-4493-8671-f85f9fa1da64"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.55905511811024,\n",
              " 'f1': 0.7720383798735819,\n",
              " 'precision': 0.7810725814480683,\n",
              " 'recall': 0.7755905511811023}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCtlcfsJeNOt",
        "outputId": "ba7356e7-1369-40cc-97c1-e79f3f33284c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "Again, the only difference will be the layer(s) we use between the embedding and the output.\n"
      ],
      "metadata": {
        "id": "_--Y5-kceXeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an RNN using GRU cell\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(units=64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(units=64, return_sequences=True)(x)   # when we're stacking RNN cells together, we need to set return_sequences = True\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(units=64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(units=64, activation=\"relu\")(x)\n",
        "\n",
        "outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "5R5nexlIgt-m"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF-EyzCOUj7I",
        "outputId": "3c2763c2-fd5a-4301-b546-2565137f46b4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "bO8CBKeiY5cm"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_3_GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9iVaZ6BZpuO",
        "outputId": "e8670216-e90c-49cd-b152-3b740118c97a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20220720-075923\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 8ms/step - loss: 0.1526 - accuracy: 0.9418 - val_loss: 0.7339 - val_accuracy: 0.7717\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0849 - accuracy: 0.9701 - val_loss: 0.9432 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0725 - accuracy: 0.9727 - val_loss: 0.9798 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0651 - accuracy: 0.9753 - val_loss: 0.9155 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.0604 - accuracy: 0.9759 - val_loss: 0.9463 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLqfeUXnaiTx",
        "outputId": "a51ac982-a0a4-47ad-afa3-0debf26ac39b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5349235e-02],\n",
              "       [9.6070325e-01],\n",
              "       [9.9958271e-01],\n",
              "       [5.1773131e-02],\n",
              "       [1.7986345e-04],\n",
              "       [9.9679464e-01],\n",
              "       [1.1854186e-01],\n",
              "       [9.9986303e-01],\n",
              "       [9.9974984e-01],\n",
              "       [7.3245078e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOIsZbVDaw3e",
        "outputId": "8d794da4-96b3-4120-aa28-d003cb9145c0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGvYCiTybScm",
        "outputId": "952177b6-e7bc-486a-b165-52ccc871e62b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7665280970313494,\n",
              " 'precision': 0.7714293151588276,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We08hr8-bzpl",
        "outputId": "58c4ff79-6412-4c66-cad7-319f99f8e2ea"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('bleh')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k72iZuY_b48o",
        "outputId": "535504fc-2c39-4209-a727-b10a435d9b33"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bleh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidirectional RNN model\n",
        "\n",
        "[`tf.keras.layers.Bidirectional`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional)\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "> 🔑 **Note:** You can use the `Bidirectional` wrapper on any RNN cell in TensorFlow. For example, `layers.Bidirectional(layers.GRU(64))` creates a bidirectional GRU cell."
      ],
      "metadata": {
        "id": "tqT-pHxrjMbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a bidirectional RNN\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Bidirectional(layers.LSTM(units=64, return_sequences=True))(x)\n",
        "# print(x.shape)\n",
        "x = layers.Bidirectional(layers.LSTM(units=64))(x)\n",
        "# print(x.shape)\n",
        "\n",
        "outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "metadata": {
        "id": "dhlx79Nmmitt"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fcFSl8Iq_Te",
        "outputId": "44a659ce-541f-4871-8817-fec9d2aeac24"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "g005vFdvrK4Q"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_bidirectional\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hoC9JLfr3bn",
        "outputId": "3d510105-adb1-4e83-98c5-fb8317072214"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20220720-075933\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 11ms/step - loss: 0.1088 - accuracy: 0.9686 - val_loss: 0.9298 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0547 - accuracy: 0.9781 - val_loss: 1.2309 - val_accuracy: 0.7625\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0488 - accuracy: 0.9791 - val_loss: 1.3381 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0428 - accuracy: 0.9813 - val_loss: 1.3051 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0446 - accuracy: 0.9794 - val_loss: 1.2704 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIzkymiXshIt",
        "outputId": "b3ac38ca-aab2-4f44-8afb-17267c1fdea2"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.4142737e-03],\n",
              "       [8.6668682e-01],\n",
              "       [9.9996686e-01],\n",
              "       [2.9042989e-02],\n",
              "       [8.3620580e-05],\n",
              "       [9.9917608e-01],\n",
              "       [1.3575248e-03],\n",
              "       [9.9998879e-01],\n",
              "       [9.9998283e-01],\n",
              "       [7.4255532e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_4 pred probs into labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-6hLiQs1Ad",
        "outputId": "ec84bfe2-e8f5-4fdd-8f36-180e8517033e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_4 results\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                  y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjwnS9ErtH01",
        "outputId": "cc97dc32-751f-48fd-8f33-0f03777e6b16"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'f1': 0.7688960790251899,\n",
              " 'precision': 0.7747861668850706,\n",
              " 'recall': 0.7716535433070866}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbtkwo0StYvg",
        "outputId": "069f1b3a-9b4f-4a79-84ae-e749afb1faeb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7665280970313494,\n",
              " 'precision': 0.7714293151588276,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following: \n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers (typically Conv1D + pooling) -> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "You might be thinking \"that just looks like the architecture layout we've been using for the other models...\"\n",
        "\n",
        "And you'd be right.\n",
        "\n",
        "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D) layer followed by a [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) layer.\n",
        "\n",
        "> 📖 **Resource:** The intuition here is explained succinctly in the paper [*Understanding Convolutional Neural Networks for Text Classification*](https://www.aclweb.org/anthology/W18-5408.pdf), where they state that CNNs classify text through the following steps:\n",
        "1. 1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
        "2. Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "3. The rest of the network classifies the text based on this information."
      ],
      "metadata": {
        "id": "x2PCeb4kuDc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Conv1D"
      ],
      "metadata": {
        "id": "2LJrYfIQyVcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"]))    # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "                        kernel_size=5,    # aka ngram of 5 (i.e. looks at 5 words at a time)\n",
        "                        strides=1,        # default\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"same\")  # default = 'valid', the output shape is smaller than the input shape... 'same' means output shape is same as the input shape\n",
        "conv_1d_output = conv_1d(embedding_test)    # pass test embedding through conv_1d layer\n",
        "max_pool = layers.GlobalMaxPooling1D()\n",
        "max_pool_output = max_pool(conv_1d_output)  # equivalent to \"get the most important feature\" or \"get the feature with highest value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqtewlpiD7iy",
        "outputId": "cf1f725a-b1d5-4816-a086-0b28bdf8cc56"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE:** ***'same' and 'valid' padding difference:***\n",
        "[stackoverflow answer](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t#:~:text=To%20sum%20up%2C%20'valid',same'%20padding%20means%20using%20padding.)"
      ],
      "metadata": {
        "id": "AcBodck7K0cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdpgDemHH6ri",
        "outputId": "cd15e582-494e-44b6-e9d5-939a04f10371"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00767935, -0.08610959,  0.01838144, ..., -0.04509318,\n",
              "         -0.03022609, -0.07111328],\n",
              "        [-0.01852835, -0.01851673,  0.03740028, ..., -0.03926198,\n",
              "          0.0237287 ,  0.01528002],\n",
              "        [ 0.04817761, -0.05787547, -0.01110806, ..., -0.04036497,\n",
              "         -0.07805195, -0.0361486 ],\n",
              "        ...,\n",
              "        [ 0.00887255,  0.00051377,  0.02100966, ...,  0.0082314 ,\n",
              "         -0.02989312,  0.00505195],\n",
              "        [ 0.00887255,  0.00051377,  0.02100966, ...,  0.0082314 ,\n",
              "         -0.02989312,  0.00505195],\n",
              "        [ 0.00887255,  0.00051377,  0.02100966, ...,  0.0082314 ,\n",
              "         -0.02989312,  0.00505195]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_1d_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY9qAv82L5xe",
        "outputId": "a5436946-b908-4346-ddd9-4ef9fded6704"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 64), dtype=float32, numpy=\n",
              "array([[[0.01596651, 0.        , 0.        , 0.        , 0.02815423,\n",
              "         0.05527361, 0.02786904, 0.        , 0.04469164, 0.        ,\n",
              "         0.03332338, 0.05359464, 0.        , 0.02467459, 0.01003791,\n",
              "         0.01805171, 0.        , 0.        , 0.01027194, 0.        ,\n",
              "         0.0669373 , 0.        , 0.        , 0.02556402, 0.01759217,\n",
              "         0.02698524, 0.04963886, 0.02309605, 0.03871229, 0.07257203,\n",
              "         0.        , 0.03836748, 0.        , 0.        , 0.06185272,\n",
              "         0.        , 0.05550434, 0.00264016, 0.00886428, 0.00497754,\n",
              "         0.00424889, 0.00039165, 0.03421456, 0.        , 0.        ,\n",
              "         0.00251929, 0.06149445, 0.01276842, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.05182439, 0.00193843, 0.        ,\n",
              "         0.00186551, 0.        , 0.        , 0.0261021 , 0.04502288,\n",
              "         0.03871666, 0.        , 0.        , 0.        ],\n",
              "        [0.04261844, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.03302697, 0.04535618, 0.07332428, 0.03689098, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.00207887, 0.        , 0.        , 0.05345024,\n",
              "         0.06504127, 0.00489129, 0.        , 0.        , 0.06812672,\n",
              "         0.        , 0.00205663, 0.        , 0.02040219, 0.04195688,\n",
              "         0.        , 0.01938313, 0.00882106, 0.        , 0.04141667,\n",
              "         0.        , 0.        , 0.02896743, 0.02179702, 0.        ,\n",
              "         0.        , 0.06649683, 0.05858637, 0.        , 0.        ,\n",
              "         0.        , 0.01452466, 0.        , 0.05941134, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.01663488, 0.09892935, 0.        , 0.0177687 ,\n",
              "         0.02470893, 0.        , 0.        , 0.06866144],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.03459411, 0.        , 0.        , 0.02188746, 0.        ,\n",
              "         0.12309861, 0.        , 0.0725013 , 0.01629254, 0.        ,\n",
              "         0.        , 0.        , 0.04094567, 0.01864722, 0.06228843,\n",
              "         0.04129085, 0.0050005 , 0.        , 0.08045674, 0.        ,\n",
              "         0.        , 0.        , 0.03530228, 0.01680975, 0.09142193,\n",
              "         0.        , 0.00286271, 0.00781574, 0.        , 0.04408384,\n",
              "         0.        , 0.        , 0.04282183, 0.        , 0.        ,\n",
              "         0.        , 0.01374052, 0.01695613, 0.        , 0.        ,\n",
              "         0.01922715, 0.        , 0.        , 0.05117336, 0.0426743 ,\n",
              "         0.        , 0.00508198, 0.05109009, 0.04312146, 0.        ,\n",
              "         0.0303507 , 0.05229007, 0.04806157, 0.03019245, 0.        ,\n",
              "         0.01872894, 0.02496671, 0.01701355, 0.06045954],\n",
              "        [0.        , 0.0095822 , 0.        , 0.        , 0.        ,\n",
              "         0.03122948, 0.        , 0.        , 0.00286306, 0.        ,\n",
              "         0.06307751, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0233355 , 0.        , 0.02838592, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.03199793, 0.02649907,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.02863213,\n",
              "         0.        , 0.06815179, 0.        , 0.        , 0.01891513,\n",
              "         0.03018926, 0.00812078, 0.0073354 , 0.        , 0.        ,\n",
              "         0.0166781 , 0.07002001, 0.04105904, 0.        , 0.        ,\n",
              "         0.01047547, 0.        , 0.00735595, 0.00672829, 0.        ,\n",
              "         0.        , 0.        , 0.04820318, 0.        , 0.        ,\n",
              "         0.01155849, 0.02333632, 0.05198846, 0.        , 0.02654767,\n",
              "         0.00404411, 0.05462471, 0.01309726, 0.02800905],\n",
              "        [0.        , 0.03712017, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02231963, 0.        , 0.03402032, 0.00129034,\n",
              "         0.        , 0.        , 0.03279758, 0.0327512 , 0.06520073,\n",
              "         0.02002907, 0.00525814, 0.03196202, 0.02448253, 0.01305983,\n",
              "         0.        , 0.        , 0.00734255, 0.02874174, 0.06096679,\n",
              "         0.        , 0.        , 0.05087449, 0.02580368, 0.        ,\n",
              "         0.        , 0.00831928, 0.        , 0.        , 0.0994173 ,\n",
              "         0.06534915, 0.03224451, 0.        , 0.08229512, 0.        ,\n",
              "         0.02905236, 0.00311585, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.01971249, 0.        , 0.05485136,\n",
              "         0.01982999, 0.        , 0.        , 0.01890815, 0.        ,\n",
              "         0.        , 0.03465626, 0.00869194, 0.        , 0.        ,\n",
              "         0.0468313 , 0.        , 0.        , 0.03698803],\n",
              "        [0.00185241, 0.02762489, 0.00898276, 0.04187524, 0.02035213,\n",
              "         0.00695345, 0.        , 0.        , 0.00068841, 0.00828032,\n",
              "         0.03539889, 0.        , 0.01146064, 0.        , 0.02949619,\n",
              "         0.01758807, 0.00490577, 0.00335345, 0.04286645, 0.        ,\n",
              "         0.00130978, 0.02618702, 0.00166841, 0.00338309, 0.07429171,\n",
              "         0.02665251, 0.        , 0.        , 0.00400234, 0.        ,\n",
              "         0.        , 0.06968398, 0.00271271, 0.        , 0.04154149,\n",
              "         0.00605527, 0.00327683, 0.        , 0.00612525, 0.        ,\n",
              "         0.05660924, 0.00137279, 0.01572986, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.01301423, 0.00226815, 0.02671391,\n",
              "         0.        , 0.        , 0.        , 0.04078113, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.01691483, 0.01470251,\n",
              "         0.03989697, 0.0618264 , 0.04113546, 0.00772187],\n",
              "        [0.        , 0.04036106, 0.00552604, 0.        , 0.        ,\n",
              "         0.02539326, 0.0092341 , 0.        , 0.04298991, 0.01819955,\n",
              "         0.02586555, 0.        , 0.01717906, 0.01033328, 0.0037358 ,\n",
              "         0.01075665, 0.        , 0.0213669 , 0.        , 0.        ,\n",
              "         0.00230433, 0.03969556, 0.03127897, 0.0077816 , 0.05343281,\n",
              "         0.00651202, 0.        , 0.        , 0.00357185, 0.        ,\n",
              "         0.        , 0.05215495, 0.02599027, 0.        , 0.01646116,\n",
              "         0.04182529, 0.00448789, 0.        , 0.01304659, 0.        ,\n",
              "         0.06005473, 0.04398368, 0.03495837, 0.01464803, 0.        ,\n",
              "         0.        , 0.03347953, 0.02739677, 0.00878034, 0.00187742,\n",
              "         0.        , 0.        , 0.00478717, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.02912102, 0.        , 0.07524598,\n",
              "         0.02781007, 0.06143497, 0.        , 0.        ],\n",
              "        [0.        , 0.04674673, 0.01016434, 0.        , 0.        ,\n",
              "         0.02588819, 0.00629672, 0.        , 0.02908912, 0.00564993,\n",
              "         0.03616503, 0.        , 0.00742943, 0.01039916, 0.02574047,\n",
              "         0.03865358, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01354508, 0.02233165, 0.05469437, 0.00397928, 0.03105387,\n",
              "         0.0048594 , 0.        , 0.        , 0.01116244, 0.01207746,\n",
              "         0.        , 0.04483974, 0.04611164, 0.        , 0.        ,\n",
              "         0.04308078, 0.00074042, 0.        , 0.03815134, 0.        ,\n",
              "         0.00846197, 0.03311209, 0.046202  , 0.        , 0.02101549,\n",
              "         0.        , 0.02840488, 0.03228514, 0.        , 0.02116164,\n",
              "         0.        , 0.        , 0.        , 0.02990593, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03993756,\n",
              "         0.03118501, 0.01905106, 0.01453959, 0.        ],\n",
              "        [0.        , 0.04674673, 0.01016435, 0.        , 0.        ,\n",
              "         0.02588818, 0.00629673, 0.        , 0.02908913, 0.00564993,\n",
              "         0.03616503, 0.        , 0.00742944, 0.01039916, 0.02574048,\n",
              "         0.03865358, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01354508, 0.02233165, 0.05469438, 0.00397927, 0.03105388,\n",
              "         0.0048594 , 0.        , 0.        , 0.01116244, 0.01207746,\n",
              "         0.        , 0.04483973, 0.04611164, 0.        , 0.        ,\n",
              "         0.04308079, 0.00074042, 0.        , 0.03815134, 0.        ,\n",
              "         0.00846196, 0.03311209, 0.046202  , 0.        , 0.0210155 ,\n",
              "         0.        , 0.02840488, 0.03228515, 0.        , 0.02116164,\n",
              "         0.        , 0.        , 0.        , 0.02990593, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03993756,\n",
              "         0.03118501, 0.01905106, 0.01453958, 0.        ],\n",
              "        [0.        , 0.04674674, 0.01016435, 0.        , 0.        ,\n",
              "         0.02588818, 0.00629673, 0.        , 0.02908913, 0.00564993,\n",
              "         0.03616503, 0.        , 0.00742944, 0.01039916, 0.02574047,\n",
              "         0.03865359, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01354508, 0.02233165, 0.05469437, 0.00397928, 0.03105388,\n",
              "         0.0048594 , 0.        , 0.        , 0.01116245, 0.01207746,\n",
              "         0.        , 0.04483973, 0.04611164, 0.        , 0.        ,\n",
              "         0.04308078, 0.00074042, 0.        , 0.03815134, 0.        ,\n",
              "         0.00846197, 0.03311209, 0.046202  , 0.        , 0.02101548,\n",
              "         0.        , 0.02840488, 0.03228515, 0.        , 0.02116165,\n",
              "         0.        , 0.        , 0.        , 0.02990592, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03993756,\n",
              "         0.03118501, 0.01905106, 0.01453959, 0.        ],\n",
              "        [0.        , 0.04674674, 0.01016435, 0.        , 0.        ,\n",
              "         0.02588818, 0.00629674, 0.        , 0.02908913, 0.00564993,\n",
              "         0.03616503, 0.        , 0.00742944, 0.01039915, 0.02574047,\n",
              "         0.03865358, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01354508, 0.02233165, 0.05469437, 0.00397928, 0.03105387,\n",
              "         0.0048594 , 0.        , 0.        , 0.01116244, 0.01207746,\n",
              "         0.        , 0.04483973, 0.04611164, 0.        , 0.        ,\n",
              "         0.04308079, 0.00074042, 0.        , 0.03815134, 0.        ,\n",
              "         0.00846197, 0.03311209, 0.04620199, 0.        , 0.0210155 ,\n",
              "         0.        , 0.02840488, 0.03228514, 0.        , 0.02116164,\n",
              "         0.        , 0.        , 0.        , 0.02990592, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03993756,\n",
              "         0.03118501, 0.01905105, 0.01453959, 0.        ],\n",
              "        [0.        , 0.04674673, 0.01016435, 0.        , 0.        ,\n",
              "         0.02588818, 0.00629673, 0.        , 0.02908913, 0.00564993,\n",
              "         0.03616503, 0.        , 0.00742944, 0.01039916, 0.02574047,\n",
              "         0.03865358, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01354508, 0.02233164, 0.05469437, 0.00397928, 0.03105387,\n",
              "         0.0048594 , 0.        , 0.        , 0.01116244, 0.01207746,\n",
              "         0.        , 0.04483972, 0.04611164, 0.        , 0.        ,\n",
              "         0.04308078, 0.00074042, 0.        , 0.03815134, 0.        ,\n",
              "         0.00846197, 0.03311209, 0.046202  , 0.        , 0.0210155 ,\n",
              "         0.        , 0.02840488, 0.03228515, 0.        , 0.02116164,\n",
              "         0.        , 0.        , 0.        , 0.02990593, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03993756,\n",
              "         0.03118501, 0.01905106, 0.01453958, 0.        ],\n",
              "        [0.        , 0.04674674, 0.01016435, 0.        , 0.        ,\n",
              "         0.02588819, 0.00629673, 0.        , 0.02908913, 0.00564993,\n",
              "         0.03616503, 0.        , 0.00742943, 0.01039916, 0.02574048,\n",
              "         0.03865359, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01354507, 0.02233164, 0.05469437, 0.00397928, 0.03105387,\n",
              "         0.0048594 , 0.        , 0.        , 0.01116244, 0.01207746,\n",
              "         0.        , 0.04483973, 0.04611164, 0.        , 0.        ,\n",
              "         0.04308079, 0.00074042, 0.        , 0.03815134, 0.        ,\n",
              "         0.00846197, 0.03311209, 0.04620199, 0.        , 0.02101549,\n",
              "         0.        , 0.02840488, 0.03228514, 0.        , 0.02116165,\n",
              "         0.        , 0.        , 0.        , 0.02990593, 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.03993756,\n",
              "         0.03118501, 0.01905105, 0.01453959, 0.        ],\n",
              "        [0.        , 0.03756739, 0.00436398, 0.        , 0.        ,\n",
              "         0.01510606, 0.        , 0.        , 0.03310722, 0.00735038,\n",
              "         0.02058957, 0.        , 0.01830661, 0.        , 0.01430067,\n",
              "         0.0412107 , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.01486988, 0.02272021, 0.0538817 , 0.        , 0.0140005 ,\n",
              "         0.01858316, 0.        , 0.        , 0.01951127, 0.02069596,\n",
              "         0.        , 0.0150409 , 0.04190729, 0.        , 0.        ,\n",
              "         0.02991703, 0.        , 0.        , 0.0549574 , 0.        ,\n",
              "         0.        , 0.01635062, 0.05667806, 0.        , 0.02325008,\n",
              "         0.        , 0.02146841, 0.02513892, 0.00819343, 0.01026947,\n",
              "         0.        , 0.        , 0.        , 0.03800753, 0.01028004,\n",
              "         0.        , 0.00335553, 0.        , 0.        , 0.0253183 ,\n",
              "         0.01830025, 0.02483955, 0.01239934, 0.        ],\n",
              "        [0.        , 0.01967581, 0.01167733, 0.        , 0.00969139,\n",
              "         0.01141671, 0.        , 0.        , 0.03480188, 0.00544559,\n",
              "         0.01677545, 0.        , 0.        , 0.00135232, 0.0053686 ,\n",
              "         0.03630961, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.00849539, 0.00591894, 0.03897212, 0.0055357 , 0.00711829,\n",
              "         0.0002906 , 0.        , 0.        , 0.03205953, 0.02274213,\n",
              "         0.        , 0.02115474, 0.03563496, 0.        , 0.        ,\n",
              "         0.00751705, 0.        , 0.        , 0.04444437, 0.        ,\n",
              "         0.01209166, 0.01894432, 0.04304013, 0.        , 0.03074409,\n",
              "         0.        , 0.02254039, 0.0335321 , 0.        , 0.        ,\n",
              "         0.        , 0.01313843, 0.        , 0.02504596, 0.01023229,\n",
              "         0.        , 0.00706311, 0.        , 0.00291659, 0.0218411 ,\n",
              "         0.00599465, 0.01484921, 0.01373318, 0.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSKv9D7L93i",
        "outputId": "d6402cf8-a7e1-4a98-be9f-b079091157a9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 64), dtype=float32, numpy=\n",
              "array([[0.04261844, 0.04674674, 0.01167733, 0.04187524, 0.02815423,\n",
              "        0.05527361, 0.04535618, 0.07332428, 0.04469164, 0.01819955,\n",
              "        0.12309861, 0.05359464, 0.0725013 , 0.0327512 , 0.06520073,\n",
              "        0.0412107 , 0.0233355 , 0.04094567, 0.04286645, 0.06228843,\n",
              "        0.0669373 , 0.03969556, 0.05469438, 0.08045674, 0.07429171,\n",
              "        0.02698524, 0.04963886, 0.05087449, 0.03871229, 0.09142193,\n",
              "        0.        , 0.06968398, 0.04611164, 0.        , 0.0994173 ,\n",
              "        0.06534915, 0.05550434, 0.04282183, 0.08229512, 0.00497754,\n",
              "        0.06005473, 0.07002001, 0.05858637, 0.01464803, 0.03074409,\n",
              "        0.01922715, 0.06149445, 0.0335321 , 0.05941134, 0.05485136,\n",
              "        0.01982999, 0.01313843, 0.05182439, 0.04312146, 0.01028004,\n",
              "        0.0303507 , 0.05229007, 0.09892935, 0.03019245, 0.07524598,\n",
              "        0.0468313 , 0.0618264 , 0.04113546, 0.06866144]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1-dimensional CNN to model sequences\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(units=64, activation=\"relu\")(x)\n",
        "\n",
        "outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_conv1d\")"
      ],
      "metadata": {
        "id": "e-hmb7trMx1Y"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XwyF8KSPRAv",
        "outputId": "e0ecf8d4-bed4-4c6a-ade7-3e9523a85950"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv1d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "EMACtYC3PVzZ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "BATCH_SIZE = 32\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              batch_size=32,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_5_conv1d\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j42kR35oP8Gi",
        "outputId": "b0e8a68e-458f-402e-8c4c-32335c2ecf3d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_conv1d/20220720-075953\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 3s 6ms/step - loss: 0.1214 - accuracy: 0.9566 - val_loss: 0.9318 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 1.0762 - val_accuracy: 0.7638\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9753 - val_loss: 1.1747 - val_accuracy: 0.7559\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0554 - accuracy: 0.9765 - val_loss: 1.2757 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0504 - accuracy: 0.9783 - val_loss: 1.2585 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8H8AAfpQ76_",
        "outputId": "b9cd69b0-5864-4edf-c6aa-4e51249455a2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.9295482e-01],\n",
              "       [1.7571048e-01],\n",
              "       [9.9988425e-01],\n",
              "       [3.3408999e-02],\n",
              "       [1.4816068e-08],\n",
              "       [9.9773860e-01],\n",
              "       [9.5493472e-01],\n",
              "       [9.9993610e-01],\n",
              "       [9.9999988e-01],\n",
              "       [8.8120055e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_5 pred probs into labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVc4oDpMRNbw",
        "outputId": "e53812ca-51f9-4221-c732-ce6123429611"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the results of model_5\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwHKzM23Rg_w",
        "outputId": "a6891fbc-3b38-4d6f-f47d-4f2aaa498f71"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'f1': 0.7487994714665389,\n",
              " 'precision': 0.7511704709318223,\n",
              " 'recall': 0.7506561679790026}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkZiGBwiR0Xi",
        "outputId": "f51d632e-ad72-4e5f-d701-533caa9a1e82"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-USE-tensorflow-hub-encoder-decoder-model.png)\n",
        "*The feature extractor model we're building through the eyes of an **encoder/decoder** model.*\n",
        "\n",
        "**Refer:** https://tfhub.dev/google/universal-sentence-encoder/4"
      ],
      "metadata": {
        "id": "iru4fsW1S5BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"Potato patato pleh phew\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLziAaF2aEIF",
        "outputId": "9969c898-8b25-4108-af69-2e426ddd821a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrDrJO8PdIxG",
        "outputId": "ff42aeff-ba14-4961-d1a6-dcb5c680d46f"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.01157028,  0.0248591 ,  0.02878048, ..., -0.00186124,\n",
              "         0.02315826, -0.01485021],\n",
              "       [ 0.00136726,  0.04412336,  0.04159484, ..., -0.03636198,\n",
              "         0.0215806 , -0.00588427]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxYDOU3_d01k",
        "outputId": "dbda27a1-8e5e-4094-c9e2-2608a09125a9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a keras layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "metadata": {
        "id": "G1fnB5DCd92b"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using sequential API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(units=64, activation=\"relu\"),\n",
        "  layers.Dense(units=1, activation=\"sigmoid\", name=\"output_layer\"),\n",
        "], name=\"model_6_USE\")"
      ],
      "metadata": {
        "id": "9Fp93B8zfosF"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "UERDBC98gK_W"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNTCtjUPggLu",
        "outputId": "60ec2632-e7ef-4ee1-a50d-84e416959c6e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_6_USE\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKzG4sv-gjjU",
        "outputId": "ca98d7fe-f8fc-4cbe-90d4-80a3cf65aa44"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_USE/20220720-080019\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 13ms/step - loss: 0.5077 - accuracy: 0.7872 - val_loss: 0.4527 - val_accuracy: 0.7992\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.4163 - accuracy: 0.8130 - val_loss: 0.4391 - val_accuracy: 0.8045\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4018 - accuracy: 0.8221 - val_loss: 0.4387 - val_accuracy: 0.8097\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3935 - accuracy: 0.8262 - val_loss: 0.4348 - val_accuracy: 0.8071\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3879 - accuracy: 0.8295 - val_loss: 0.4268 - val_accuracy: 0.8163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_4GeZLbiDaa",
        "outputId": "16040f48-d64f-43d7-9816-7be2f0580683"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20007166],\n",
              "       [0.7766229 ],\n",
              "       [0.984145  ],\n",
              "       [0.20315126],\n",
              "       [0.75567925],\n",
              "       [0.7253024 ],\n",
              "       [0.97658384],\n",
              "       [0.9755408 ],\n",
              "       [0.9235462 ],\n",
              "       [0.11363076]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py_GN47oiIpN",
        "outputId": "8cce00c7-59b6-4d40-9c04-9355bd8e80f1"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqHWTSmCiL_1",
        "outputId": "9ba2a66d-8f29-4641-93d7-79bfdb62f9ce"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8149048737121865,\n",
              " 'precision': 0.8181574920275534,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDpjNSQqiOsL",
        "outputId": "f9e17170-d246-4017-83b4-16ca187279ea"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when we don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
      ],
      "metadata": {
        "id": "AeTJVjQ9iRhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 🔑 **Note:** Be *very* careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie."
      ],
      "metadata": {
        "id": "wueTjaytj9gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET \n",
        "\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "\n",
        "# # train_10_percent.head(), len(train_10_percent)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "metadata": {
        "id": "Ap4NRi2WkNss"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "metadata": {
        "id": "p4HZHbTFpI1h"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of each label in the updated training data subset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBkKgv3yqCPd",
        "outputId": "d74f09c6-bd8d-47ab-a24c-6dd1a68a0042"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled[\"target\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1sYU5FRlUO3",
        "outputId": "9d9284b6-5702-44a9-9d81-72acfd915aba"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To recreate a model the same as a previous model we've created, we can use the `tf.keras.models.clone_model()` method, see more here: https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model"
      ],
      "metadata": {
        "id": "k0vGZL0KlUpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's build a model the same as model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFzb7q4LliH7",
        "outputId": "495acf50-0668-4c3b-d9bd-b8370c15e0fc"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgupgqxmR5U",
        "outputId": "97e4ffa7-24ac-4d5c-99c9-7ded81e1de4c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20220720-080045\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 5s 55ms/step - loss: 0.6717 - accuracy: 0.6438 - val_loss: 0.6509 - val_accuracy: 0.7244\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.5995 - accuracy: 0.8029 - val_loss: 0.5905 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.5219 - accuracy: 0.8088 - val_loss: 0.5331 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.4598 - accuracy: 0.8219 - val_loss: 0.5026 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 20ms/step - loss: 0.4198 - accuracy: 0.8307 - val_loss: 0.4904 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzP5IkaDmlNt",
        "outputId": "d70a902b-94a1-4d28-849d-f9414e06a453"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20228526],\n",
              "       [0.59397286],\n",
              "       [0.92162156],\n",
              "       [0.40631747],\n",
              "       [0.5329078 ],\n",
              "       [0.67895025],\n",
              "       [0.8896933 ],\n",
              "       [0.7919374 ],\n",
              "       [0.85356516],\n",
              "       [0.16019765]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWFvexIVmr_D",
        "outputId": "f8dc312a-7c13-41fa-e3cd-0a42e916a2eb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalaute model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT2CPv6Imt5-",
        "outputId": "c89445c9-6534-4c8d-83ac-14c5339497aa"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'f1': 0.7845514310000248,\n",
              " 'precision': 0.7872311306036273,\n",
              " 'recall': 0.7860892388451444}"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ5XBvglmwB5",
        "outputId": "2cc583b0-d236-432f-84bc-d6f8dd8e020c"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8149048737121865,\n",
              " 'precision': 0.8181574920275534,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the peformance of each of our models"
      ],
      "metadata": {
        "id": "YYzOsuu6myo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": model_3_results,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "O-jIxs7unIHK",
        "outputId": "e1683568-45a6-4453-e390-d8d27d9fc742"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  accuracy  precision    recall        f1\n",
              "0_baseline                       79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   78.346457   0.787212  0.783465  0.780780\n",
              "2_lstm                           77.559055   0.781073  0.775591  0.772038\n",
              "3_gru                            76.902887   0.771429  0.769029  0.766528\n",
              "4_bidirectional                  77.165354   0.774786  0.771654  0.768896\n",
              "5_conv1d                         75.065617   0.751170  0.750656  0.748799\n",
              "6_tf_hub_use_encoder             81.627297   0.818157  0.816273  0.814905\n",
              "7_tf_hub_use_encoder_10_percent  78.608924   0.787231  0.786089  0.784551"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12d9539d-48b8-4850-9b95-f074e22bf852\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>78.346457</td>\n",
              "      <td>0.787212</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.780780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>77.559055</td>\n",
              "      <td>0.781073</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.772038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>76.902887</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.766528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>77.165354</td>\n",
              "      <td>0.774786</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.768896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>75.065617</td>\n",
              "      <td>0.751170</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>81.627297</td>\n",
              "      <td>0.818157</td>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.814905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>78.608924</td>\n",
              "      <td>0.787231</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.784551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12d9539d-48b8-4850-9b95-f074e22bf852')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12d9539d-48b8-4850-9b95-f074e22bf852 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12d9539d-48b8-4850-9b95-f074e22bf852');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Fi9FuvwdnQc1",
        "outputId": "1bafbcc4-5200-44a1-8b70-b4a605f349fa"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 accuracy  precision    recall        f1\n",
              "0_baseline                       0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                   0.783465   0.787212  0.783465  0.780780\n",
              "2_lstm                           0.775591   0.781073  0.775591  0.772038\n",
              "3_gru                            0.769029   0.771429  0.769029  0.766528\n",
              "4_bidirectional                  0.771654   0.774786  0.771654  0.768896\n",
              "5_conv1d                         0.750656   0.751170  0.750656  0.748799\n",
              "6_tf_hub_use_encoder             0.816273   0.818157  0.816273  0.814905\n",
              "7_tf_hub_use_encoder_10_percent  0.786089   0.787231  0.786089  0.784551"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8772c098-a0e3-43e2-9c34-203441126642\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.787212</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.780780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.781073</td>\n",
              "      <td>0.775591</td>\n",
              "      <td>0.772038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.769029</td>\n",
              "      <td>0.766528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.774786</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.768896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.751170</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.818157</td>\n",
              "      <td>0.816273</td>\n",
              "      <td>0.814905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.787231</td>\n",
              "      <td>0.786089</td>\n",
              "      <td>0.784551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8772c098-a0e3-43e2-9c34-203441126642')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8772c098-a0e3-43e2-9c34-203441126642 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8772c098-a0e3-43e2-9c34-203441126642');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "iQEX3vxWovH2",
        "outputId": "7645b474-b8b2-4be6-9588-984e9e7269f0"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc2e9b00d90>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "Qr6OpjA2qooG",
        "outputId": "63a5504e-855f-43f8-d72b-1d95cf5ff065"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc279253c10>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading our model training logs to TesnorBoard.dev\n",
        "We can further inspect our model's performance using TensorBoard.dev: https://tensorboard.dev/"
      ],
      "metadata": {
        "id": "cTnkC1VUq7AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View TensorBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
        "# Upload TensorBoard dev records\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP Modelling Experiments\" \\\n",
        "  --description \"Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset\" \\\n",
        "  --one_shot    # exit the uploader once uploading is finished"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bievd5q2tV4z",
        "outputId": "bcb1177c-5c93-4e99-ec22-3f48bc39324b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./model_logs/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=Op5B0Dth8pW3d9Q5blcBwLFW77v2CT&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AdQt8qhZTWLzZ-BZsjOLkf2Cs9RHkAUFNDP-0WGlDhXN4D3uck5tKqDpxmI\n",
            "\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/EennjhZhQyq29Dg106YyPA/\n",
            "\n",
            "\u001b[1m[2022-07-20T08:02:59]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2022-07-20T08:03:05]\u001b[0m Total uploaded: 210 scalars, 0 tensors, 7 binary objects (2.7 MB)\n",
            "\u001b[1m[2022-07-20T08:03:05]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/EennjhZhQyq29Dg106YyPA/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> For larger scale experiments and a whole bunch more tracking options, check out Weights & Biases: https://wandb.ai/site"
      ],
      "metadata": {
        "id": "obcmt8O8ti7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous TensorBoard Dev experiments we've run...\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAb0U9_ht2Ah",
        "outputId": "720051e7-c4aa-4701-8416-eaa27861ee7b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://tensorboard.dev/experiment/EennjhZhQyq29Dg106YyPA/\n",
            "\tName                 NLP Modelling Experiments\n",
            "\tDescription          Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset\n",
            "\tId                   EennjhZhQyq29Dg106YyPA\n",
            "\tCreated              2022-07-20 08:02:59 (19 seconds ago)\n",
            "\tUpdated              2022-07-20 08:03:05 (13 seconds ago)\n",
            "\tRuns                 14\n",
            "\tTags                 5\n",
            "\tScalars              210\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  2874992\n",
            "https://tensorboard.dev/experiment/BKLwRgUgRpKgggGEODgfBA/\n",
            "\tName                 NLP Modelling Experiments\n",
            "\tDescription          Comparing multiple different types of model architectures on the Kaggle Tweets text classification dataset\n",
            "\tId                   BKLwRgUgRpKgggGEODgfBA\n",
            "\tCreated              2022-07-19 23:06:38 (8 hours ago)\n",
            "\tUpdated              2022-07-19 23:06:47 (8 hours ago)\n",
            "\tRuns                 18\n",
            "\tTags                 5\n",
            "\tScalars              270\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  4723522\n",
            "https://tensorboard.dev/experiment/ONkzcro8Teeim2R7hb4sZA/\n",
            "\tName                 Fine-tuning EfficientNetB0 on all Food101 Data\n",
            "\tDescription          Training results for fine-tuning EfficientNetB0 on Food101 Data with learning rate 0.0001\n",
            "\tId                   ONkzcro8Teeim2R7hb4sZA\n",
            "\tCreated              2022-07-16 11:38:51\n",
            "\tUpdated              2022-07-16 11:38:52\n",
            "\tRuns                 4\n",
            "\tTags                 4\n",
            "\tScalars              42\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  0\n",
            "https://tensorboard.dev/experiment/jUlqKWZ6QUqZpWlurV3yiQ/\n",
            "\tName                 Transfer Learning Experiments with 10 Food101 Classes\n",
            "\tDescription          A series of different transfer learning experiments with varying amounts of data and fine-tuning.\n",
            "\tId                   jUlqKWZ6QUqZpWlurV3yiQ\n",
            "\tCreated              2022-07-13 08:11:05\n",
            "\tUpdated              2022-07-13 08:11:13\n",
            "\tRuns                 10\n",
            "\tTags                 5\n",
            "\tScalars              162\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  4307972\n",
            "https://tensorboard.dev/experiment/AdrnQPKMQKqlKg20D9J3DQ/\n",
            "\tName                 EfficientNetB0 vs. ResNet50V2\n",
            "\tDescription          Comparing 2 different TF Hub feature extraction model architectures using 10% of the training data\n",
            "\tId                   AdrnQPKMQKqlKg20D9J3DQ\n",
            "\tCreated              2022-07-11 12:15:55\n",
            "\tUpdated              2022-07-11 12:15:57\n",
            "\tRuns                 4\n",
            "\tTags                 5\n",
            "\tScalars              60\n",
            "\tTensor bytes         0\n",
            "\tBinary object bytes  3140571\n",
            "Total: 5 experiment(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # If we need to remove previous experiments, we can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "metadata": {
        "id": "qmRNx0RtuwOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading a trained model \n",
        "\n",
        "There are two main formats to save a model to in TensorFlow:\n",
        "1. The HDF5 format\n",
        "2. The `SavedModel` format (this is the default when using TensorFlow)"
      ],
      "metadata": {
        "id": "6Y8NAsVeuHXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxRJLQonuZu3",
        "outputId": "001c29fc-58e7-42bb-e4fa-35de0aeed26c"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"/content/drive/MyDrive/Self Learning/Deep Learning/Personal notebooks/Models/NLP/model_6.h5\")"
      ],
      "metadata": {
        "id": "mYA1WC0DuPVL"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "loaded_model_6 = tf.keras.models.load_model(\"/content/drive/MyDrive/Self Learning/Deep Learning/Personal notebooks/Models/NLP/model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "metadata": {
        "id": "Oz4PQGgGoEVj"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "id": "Xz9db2IymTnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efce93c-131c-417c-d1df-79176dbea382"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 20ms/step - loss: 0.4268 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42681431770324707, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.save(\"/content/drive/MyDrive/Self Learning/Deep Learning/Personal notebooks/Models/NLP/model_6_SavedModel_format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-yOXUdLpPwS",
        "outputId": "b091d2c9-7879-4c2d-dee3-7d612e3ed42e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Learning/Deep Learning/Personal notebooks/Models/NLP/model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Self Learning/Deep Learning/Personal notebooks/Models/NLP/model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"/content/drive/MyDrive/Self Learning/Deep Learning/Personal notebooks/Models/NLP/model_6_SavedModel_format\")"
      ],
      "metadata": {
        "id": "dPfmO36epf2f"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "* And of these wrong examples which ones is it getting *most* wrong (those will predicition probabilities closest to the opposite class)\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa."
      ],
      "metadata": {
        "id": "PWI0NmzQp2PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained = loaded_model_6_SavedModel"
      ],
      "metadata": {
        "id": "pQdtE1rrtyCs"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKY-OuFSuE-v",
        "outputId": "364c584e-f8c3-4bd2-ddd7-354eb72f0d1a"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 16ms/step - loss: 0.4268 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42681434750556946, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10] # these should be in label format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0cvWQwMuP1b",
        "outputId": "60e6d572-2677-436b-fec4-6faec63837b1"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with validation sentences, validation labels and best performing model prediction labels + probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)})\n",
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mtRTSX00rO6j",
        "outputId": "52565ed7-029e-43fd-f848-3b84a0586cca"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.200072\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.776623\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.984145\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.203151\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.755679"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-098bbcbf-6f58-4f69-9b5c-be15f8f2666a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.776623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.984145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.203151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.755679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-098bbcbf-6f58-4f69-9b5c-be15f8f2666a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-098bbcbf-6f58-4f69-9b5c-be15f8f2666a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-098bbcbf-6f58-4f69-9b5c-be15f8f2666a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n",
        "most_wrong[:10]   # these are false positives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Gd_Glav_t_Bp",
        "outputId": "2cfc7692-99b8-4e3f-f203-251b993cf7dd"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
              "695  A look at state actions a year after Ferguson'...       0   1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
              "474  My phone looks like it was in a car ship airpl...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "31    0.910798  \n",
              "759   0.873682  \n",
              "49    0.848916  \n",
              "628   0.840211  \n",
              "393   0.832108  \n",
              "109   0.817787  \n",
              "209   0.806592  \n",
              "695   0.788066  \n",
              "251   0.786951  \n",
              "474   0.783343  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfa02865-2fc6-4009-9750-c64a5c96a3eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.873682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.848916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.840211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.832108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.817787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.806592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>A look at state actions a year after Ferguson'...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.788066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.786951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>My phone looks like it was in a car ship airpl...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.783343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfa02865-2fc6-4009-9750-c64a5c96a3eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfa02865-2fc6-4009-9750-c64a5c96a3eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfa02865-2fc6-4009-9750-c64a5c96a3eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_wrong.tail()   # these are false negatives"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hI6tFmilvTig",
        "outputId": "1065c06d-cc75-44b9-eab9-5fb26a193b5b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
              "233                    I get to smoke my shit in peace       1   0.0   \n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
              "\n",
              "     pred_prob  \n",
              "244   0.048281  \n",
              "233   0.045925  \n",
              "411   0.045259  \n",
              "23    0.037947  \n",
              "38    0.037771  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-562f8be0-a0c1-48fa-afd2-994baf104d5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.045259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-562f8be0-a0c1-48fa-afd2-994baf104d5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-562f8be0-a0c1-48fa-afd2-994baf104d5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-562f8be0-a0c1-48fa-afd2-994baf104d5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false positives (model predicted 1 when should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvFw8aKEvcVz",
        "outputId": "34c8a597-2340-4426-d96c-5490ae971f16"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9107978940010071\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8736815452575684\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8489157557487488\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8402112126350403\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.832107663154602\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8177874088287354\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8065918684005737\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7880663275718689\n",
            "Text:\n",
            "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7869512438774109\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7833432555198669\n",
            "Text:\n",
            "My phone looks like it was in a car ship airplane accident. Terrible\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the false negatives (model predicted 0 when should've been 1)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yHDvtJUwRNt",
        "outputId": "7ef9f337-82a8-4789-a342-0c68f4b9ea11"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06444784998893738\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.06254998594522476\n",
            "Text:\n",
            "'The way you move is like a full on rainstorm and I'm a house of cards'\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.060369573533535004\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.057092342525720596\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05563812330365181\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04828054457902908\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04592498391866684\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04525872692465782\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.037947025150060654\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03777124732732773\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions on the test dataset"
      ],
      "metadata": {
        "id": "xRXa0YfbxSeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jENjHepUxqgX",
        "outputId": "eb6ce721-836e-40e9-81dd-d973134fc30f"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1, Prob: 0.8732947111129761\n",
            "Text:\n",
            "#Ukraine #Kyiv #News Radio Free Europe/Radio Liberty: Ukraine famine monument erected in ... http://t.co/ME5u1YqH4i #Kiev #Ukrainian #Ua\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.1643519103527069\n",
            "Text:\n",
            "I'm melting a bar of chocolate under my laptop at least this fucking HELLFIRE is good for something\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.3631949722766876\n",
            "Text:\n",
            "#NowPlaying  - Lamb of God - Desolation http://t.co/mUYWttEdl6\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.6583759784698486\n",
            "Text:\n",
            "The bartender at work described a drunk man as annihilated @kdunning1919 @hsnowberger @gabrielasmith29. 16 more days\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.11169075220823288\n",
            "Text:\n",
            "Sleeping With Sirens - 2 Chord\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.25814855098724365\n",
            "Text:\n",
            "@TheElmagoo @GOPTeens @FoxNews @pattonoswalt anyone who actually plays that drinking game is in serious danger of alcohol poisoning\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.07059217244386673\n",
            "Text:\n",
            "OH MY GOSH IM AT MY AUNTS HOUSE AND THIS POST IT WAS ON HER COUNTER AND I SCREAMED BC I THOUGHT IT SAID CHRIS KELLER http://t.co/DNofWtAkAt\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.7553431391716003\n",
            "Text:\n",
            "RT  ADVISORY: Stalled Bus at EDSA Service Road Cubao SB due to mechanical trouble as of 7:53 AM. 1 lane occupied.Û_ https://t.co/HRNZKU66mm\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.061502642929553986\n",
            "Text:\n",
            "Tonight It's Going To Be Mayhem @ #4PlayThursdays. Everybody Free w/ Text. 1716 I ST NW (18+) http://t.co/omYWCLpGEf\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.14306890964508057\n",
            "Text:\n",
            "WNBA: Stars coach Dan Hughes taken off court on stretcher after collision with Danielle Robinson (ESPN) http://t.co/Jwm87uvbEf\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff"
      ],
      "metadata": {
        "id": "hHFCf1kjx13b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a function to measure the time of prediction\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \n",
        "  Args:\n",
        "  ----\n",
        "  model = a trained model\n",
        "  sample = a list of samples\n",
        "\n",
        "  Returns:\n",
        "  ----\n",
        "  total_time = total elapsed time for model to make predictions on samples\n",
        "  time_per_pred = time in seconds per single sample\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter()    # get start time\n",
        "  model.predict(samples)    # make predictions\n",
        "  end_time = time.perf_counter()    # get finish time\n",
        "  total_time = end_time-start_time    # calculuate how long predictons took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "I5RheXTlz36D"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model=model_6_pretrained,\n",
        "                                                            samples=val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7MMJzi30NTi",
        "outputId": "3d75a81e-41a0-4e08-e08f-451248c4d4cf"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.46905522999986715, 0.0006155580446192483)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fqsU5Ze0SIo",
        "outputId": "0822f5b0-8a72-403d-ca15-14ceff1be149"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.036830849000125454, 4.833444750672632e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get results for pretrained\n",
        "model_6_pretrained_results = calculate_results(y_true=val_labels,\n",
        "                                               y_pred=model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qb-8ZiN0Vry",
        "outputId": "73a9cc95-5add-4937-cc6f-f83918e97297"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'f1': 0.8149048737121865,\n",
              " 'precision': 0.8181574920275534,\n",
              " 'recall': 0.8162729658792651}"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "BlTJ8j330cuy",
        "outputId": "4a10ad09-70e9-4929-fb48-bfbca1a0cbd2"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}